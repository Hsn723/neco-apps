apiVersion: operator.victoriametrics.com/v1beta1
kind: VMRule
metadata:
  name: rook
  namespace: monitoring
  labels:
    smallset: "true"
spec:
  groups:
  - name: ceph-hdd
    rules:
      - alert: RookMetricsMissing
        expr: absent(up{job="rook",namespace="ceph-hdd"} == 1)
        for: 15m
        labels:
          severity: critical
          category: storage
        annotations:
          summary: "Rook/Ceph ceph-hdd's metrics can not be got."
          runbook: Please consider to find root causes, and solve the problems
      - alert: RookCephStatusIsError
        expr: ceph_health_status{namespace="ceph-hdd"} != 0 and ceph_health_status{namespace="ceph-hdd"} != 1
        labels:
          severity: critical
          category: storage
        for: 15m
        annotations:
          summary: "Rook/Ceph {{ $labels.namespace }}'s status is HEALTH_ERR."
          runbook: Please consider to find root causes, and solve the problems
      - alert: CephOSDIsNearlyNearFull
        expr: ceph_osd_stat_bytes_used{namespace="ceph-hdd"} / ceph_osd_stat_bytes{namespace="ceph-hdd"} > 0.8
        for: 15m
        labels:
          severity: warning
        annotations:
          summary: "Rook/Ceph {{ $labels.ceph_daemon }} in {{ $labels.namespace }} is used more than 80%."
          runbook: Please consider to find root causes, and solve the problems
  - name: ceph-ssd
    rules:
      - alert: RookMetricsMissing
        expr: absent(up{job="rook",namespace="ceph-ssd"} == 1)
        for: 15m
        labels:
          severity: critical
          category: storage
        annotations:
          summary: "Rook/Ceph ceph-ssd's metrics can not be got."
          runbook: Please consider to find root causes, and solve the problems
      - alert: RookCephStatusIsError
        expr: ceph_health_status{namespace="ceph-ssd"} != 0 and ceph_health_status{namespace="ceph-ssd"} != 1
        labels:
          severity: critical
          category: storage
        for: 15m
        annotations:
          summary: "Rook/Ceph {{ $labels.namespace }}'s status is HEALTH_ERR."
          runbook: Please consider to find root causes, and solve the problems
      - alert: CephOSDIsNearlyNearFull
        expr: ceph_osd_stat_bytes_used{namespace="ceph-ssd"} / ceph_osd_stat_bytes{namespace="ceph-ssd"} > 0.8
        for: 15m
        labels:
          severity: warning
        annotations:
          summary: "Rook/Ceph {{ $labels.ceph_daemon }} in {{ $labels.namespace }} is used more than 80%."
          runbook: Please consider to find root causes, and solve the problems
  - name: ceph-object-store
    rules:
      - alert: RookMetricsMissing
        expr: absent(up{job="rook",namespace="ceph-object-store"} == 1)
        for: 15m
        labels:
          severity: critical
          category: storage
        annotations:
          summary: "Rook/Ceph ceph-object-store's metrics can not be got."
          runbook: Please consider to find root causes, and solve the problems
      - alert: RookCephStatusIsError
        expr: ceph_health_status{namespace="ceph-object-store"} != 0 and ceph_health_status{namespace="ceph-object-store"} != 1
        labels:
          severity: critical
          category: storage
        for: 15m
        annotations:
          summary: "Rook/Ceph {{ $labels.namespace }}'s status is HEALTH_ERR."
          runbook: Please consider to find root causes, and solve the problems
      - alert: CephOSDIsNearlyNearFull
        expr: ceph_osd_stat_bytes_used{namespace="ceph-object-store"} / ceph_osd_stat_bytes{namespace="ceph-object-store"} > 0.8
        for: 15m
        labels:
          severity: warning
        annotations:
          summary: "Rook/Ceph {{ $labels.ceph_daemon }} in {{ $labels.namespace }} is used more than 80%."
          runbook: Please consider to find root causes, and solve the problems
